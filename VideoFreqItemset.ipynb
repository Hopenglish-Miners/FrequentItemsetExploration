{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib2\n",
    "import time\n",
    "import Orange\n",
    "import re\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videoTags = pd.read_json(\"video_tags.json\", orient=\"index\")\n",
    "\n",
    "lenVideoTags = len(pd.read_json(\"video_tags.json\"))\n",
    "\n",
    "textFileSentences = open(\"videosentences.basket\", \"w\")\n",
    "stopWords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]\n",
    "\n",
    "stopWordsCount = 0 \n",
    "wordsCount = 0\n",
    "for i in range(lenVideoTags):\n",
    "# for i in range(5):\n",
    "    videoSentences = videoTags[i][\"videos\"][\"sentences\"]\n",
    "    for sentence in videoSentences:\n",
    "        if sentence is not None:\n",
    "            sentenceRegex = re.findall(r\"(?i)\\b[a-z]+\\b\", sentence)\n",
    "            for word in sentenceRegex:\n",
    "                remainingLetters = [\"s\", \"ve\", \"t\", \"m\", \"re\", \"don\"]\n",
    "                if (word.lower()  not in stopWords) and (word.lower()  not in remainingLetters):\n",
    "                    textFileSentences.write(word)\n",
    "                    textFileSentences.write(\", \")\n",
    "                else:\n",
    "    #                 print \"stopWord: \", word\n",
    "                    stopWordsCount = stopWordsCount + 1\n",
    "                wordsCount = wordsCount + 1\n",
    "            textFileSentences.write(\"\\n\")\n",
    "    \n",
    "print \"stopwords count \", stopWordsCount\n",
    "print \"words count \", wordsCount\n",
    "textFileSentences.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Orange.data.Table(\"videosentences.basket\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rules = Orange.associate.AssociationRulesSparseInducer(data, support=0.007)\n",
    "print \"%4s %4s  %s\" % (\"Supp\", \"Conf\", \"Rule\")\n",
    "for r in rules:\n",
    "    print \"%5.3f %5.3f %s\" % (r.support, r.confidence, r)\n",
    "print rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len itemsets 1332\n"
     ]
    }
   ],
   "source": [
    "inducer = Orange.associate.AssociationRulesSparseInducer(support = 0.001, store_examples = True, max_item_sets=1000000)\n",
    "itemsets = inducer.get_itemsets(data)\n",
    "\n",
    "print \"Len itemsets\", len(itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lenItemsets = len(itemsets)\n",
    "\n",
    "fileWordPairsForSentences = open(\"wordPairsForSentences.txt\", \"w\")\n",
    "\n",
    "for i in range(lenItemsets):\n",
    "    itemset = [data.domain[k].name for k in itemsets[i][0]]\n",
    "    if len(itemset) > 1:\n",
    "#         print (itemset)\n",
    "        for word in itemset:\n",
    "            fileWordPairsForSentences.write(str(word))\n",
    "            fileWordPairsForSentences.write(\", \")\n",
    "        fileWordPairsForSentences.write(\"\\n\")\n",
    "\n",
    "fileWordPairsForSentences.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords count  849600\n",
      "words count  1645973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib2\n",
    "import time\n",
    "import Orange\n",
    "import re\n",
    "    \n",
    "videoTags = pd.read_json(\"video_tags.json\", orient=\"index\")\n",
    "\n",
    "lenVideoTags = len(pd.read_json(\"video_tags.json\"))\n",
    "\n",
    "textFileWords = open(\"videowords.basket\", \"w\")\n",
    "stopWords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]\n",
    "stopWordsCount = 0 \n",
    "wordsCount = 0\n",
    "for i in range(lenVideoTags):\n",
    "# for i in range(5):\n",
    "    videoWords = videoTags[i][\"videos\"][\"wordList\"]\n",
    "    if len(videoWords) > 0:\n",
    "        for word in videoWords:\n",
    "            if word is not None:\n",
    "                if (word.lower() not in stopWords):\n",
    "                    textFileWords.write(word)\n",
    "                    textFileWords.write(\", \")\n",
    "                else:\n",
    "                    stopWordsCount = stopWordsCount + 1\n",
    "\n",
    "            wordsCount = wordsCount + 1\n",
    "        textFileWords.write(\"\\n\")\n",
    "    \n",
    "print \"stopwords count \", stopWordsCount\n",
    "print \"words count \", wordsCount\n",
    "textFileWords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2 = Orange.data.Table(\"videowords.basket\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-33688dcad870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minducer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massociate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssociationRulesSparseInducer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_item_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitemsets2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minducer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_itemsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# inducer2 = Orange.associate.AssociationRulesInducer(support = 0.2, store_examples = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# itemsets = inducer.get_itemsets(data2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data2' is not defined"
     ]
    }
   ],
   "source": [
    "rules2 = Orange.associate.AssociationRulesSparseInducer(data2, support=0.2)\n",
    "print \"%4s %4s  %s\" % (\"Supp\", \"Conf\", \"Rule\")\n",
    "for r in rules2:\n",
    "    print \"%5.3f %5.3f %s\" % (r.support, r.confidence, r)\n",
    "rules2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len itemsets 197606\n"
     ]
    }
   ],
   "source": [
    "inducer2 = Orange.associate.AssociationRulesSparseInducer(support = 0.1, store_examples = True, max_item_sets=200000)\n",
    "itemsets2 = inducer2.get_itemsets(data2)\n",
    "\n",
    "# inducer2 = Orange.associate.AssociationRulesInducer(support = 0.2, store_examples = True)\n",
    "# itemsets = inducer.get_itemsets(data2)\n",
    "\n",
    "print \"Len itemsets\", len(itemsets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving fileWordPairsForWordLists\n"
     ]
    }
   ],
   "source": [
    "lenItemsets = len(itemsets2)\n",
    "\n",
    "fileWordPairsForWordLists = open(\"wordPairsForWordLists.txt\", \"w\")\n",
    "\n",
    "for i in range(lenItemsets):\n",
    "    itemset = [data2.domain[k].name for k in itemsets2[i][0]]\n",
    "    if len(itemset) > 1:\n",
    "#         print (itemset)\n",
    "        for word in itemset:\n",
    "            fileWordPairsForWordLists.write(str(word))\n",
    "            fileWordPairsForWordLists.write(\", \")\n",
    "        fileWordPairsForWordLists.write(\"\\n\")\n",
    "\n",
    "\n",
    "fileWordPairsForWordLists.close()\n",
    "print \"Done saving fileWordPairsForWordLists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<make -> can, can -> make, one -> time, time -> one, one -> get, get -> one, one -> just, just -> one, one -> just can, one just -> can, one can -> just, just -> one can, just can -> one, can -> one just, one -> just like, one just -> like, one like -> just, just -> one like, just like -> one, like -> one just, one -> can, can -> one, one -> can like, one can -> like, one like -> can, can -> one like, can like -> one, like -> one can, one -> know, know -> one, one -> like, like -> one, right -> like, like -> right, way -> can, can -> way, way -> like, like -> way, time -> get, get -> time, time -> just, just -> time, time -> can, can -> time, time -> can like, time can -> like, time like -> can, can -> time like, can like -> time, like -> time can, time -> know, know -> time, time -> like, like -> time, see -> can, can -> see, see -> like, like -> see, get -> just, just -> get, get -> just like, get just -> like, get like -> just, just -> get like, just like -> get, like -> get just, get -> can, can -> get, get -> can like, get can -> like, get like -> can, can -> get like, can like -> get, like -> get can, get -> know, know -> get, get -> like, like -> get, just -> people, people -> just, just -> can, can -> just, just -> can know, just can -> know, just know -> can, can -> just know, can know -> just, know -> just can, just -> can like, just can -> like, just like -> can, can -> just like, can like -> just, like -> just can, just -> know, know -> just, just -> know like, just know -> like, just like -> know, know -> just like, know like -> just, like -> just know, just -> go, go -> just, just -> like, like -> just, people -> can, can -> people, people -> like, like -> people, can -> know, know -> can, can -> know like, can know -> like, can like -> know, know -> can like, know like -> can, like -> can know, can -> will, will -> can, can -> like, like -> can, know -> like, like -> know, go -> like, like -> go>\n"
     ]
    }
   ],
   "source": [
    "print rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dataexploration27]",
   "language": "python",
   "name": "conda-env-dataexploration27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
